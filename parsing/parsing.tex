% !TeX root = ../thesis.tex
% !TeX spellcheck = en_US

\chapter{Parsing spreadsheet formulas}
\label{chapter:parsing}

\noindent
\begin{figure}[h]
\centerfloat
\input{parsing/refactoring-process-parsing}
\caption{This chapter details parsing, converting a string formula to an AST.}
\end{figure}


\noindent
This chapter assumes the reader is familiar with basic parser theory, a good overview of which can be found in \cite{dragonbook}.

\section{Motivation}
\label{sec:motivation}

In order to implement refactorings of spreadsheets a refactoring tool must be able to manipulate spreadsheets.
Excel exposes an API to retrieve and set the contents of a spreadsheet file, but this API only works on a formula string level.
The usual way to implement refactorings is by manipulating the original program's AST until it represents the desired program, and then print that back to a string.
Because Excel does not expose the AST or parse tree of formulas, a refactoring tool needs to contain a parser for Excel formulas.

Bumblebee relied on a parser developed over the years for previous research, however this parser suffered from having new rules added on over time, often in an inconsistent manner and not fully supporting the whole language.
Furthermore the parser interpreted some language constructs wrong and missed several features, which made implementing refactorings hard.
For example operator precedence was not taken into account, causing the formula \f{=A1 + A2 * A3} to be parsed as \f{=(A1 + A2) * A3}, which subtly and unexpectedly breaks numerous refactorings.
The existing parser thus was insufficient to implement the Bumblebee refactorings.
A better parser was needed, thus the goal of this thesis shifted toward procuring a better parser for Excel formulas.

For Bumblebee and other research on spreadsheet formulas the following design goals were formulated for the parser and grammar within the spreadsheet lab group:

\begin{enumerate}
\label{sec:designgoals}
\item The parser must be compatible with the official language
\item Produced parse trees must be suited for further manipulation and analysis with minimal post-processing required
\item The grammar must be compact enough to feasibly implement with a parser generator
\end{enumerate}

While an official grammar for Excel formulas is published \cite{ExcelOfficialGrammar}, it does not meet the above requirements for two reasons.
Firstly, it is over 30 pages long and contains hundreds of production rules and thus fails Requirement 3.
Secondly, because of the detail of the grammar and the large number of production rules the resulting parse trees are very complex and fail requirement 2.

Because there is no suitable parser and grammar available that satisfy the above requirements, I decided to clean up and partially rewrite the parser in coorporation with other members of the Spreadsheet lab.
The end result of this effort is an independent, open-source parser for Excel formulas called XLParser\footnote{https://github.com/PerfectXL/XLParser}, about which a paper was published in IEEE conference SCAM 2015 \cite{xlparser}.

\section{Improvements over existing parser}

The improvements XLParser made over the existing parser generally fall into one of the following categories:

\subsection{More frequent rejecting of invalid formulas}

XLParser is often less forgiving than the previous parser, and rejects more types of invalid formulas.
This is most prominently noticable in reference expressions, becaues the old parser does not differentiate between reference and non-reference expressions.
Therefore formulas like \f{=1 1} and \f{=LARGE((1,2,3),4)} are considered valid, while they are not and would be rejected by Excel.

\subsection{Broader parsing of valid formulas}

As can be found in Chapter \ref{chapter:evaluation}, XLParser has a very high parse success rate.

Several language features were absent in the previous parser.
Examples are ranges with multiple limits (\f{=SUM(A1:B2:C3:D4)}), structured table references (\f{=TableName[ColumnName]}), array constants \f{=SUM(\{1,2,3\})} and functions in reference expression (\f{=SUM(IF(TRUE,A1,B2):C5)}).
While sometimes these features were very rare, they still were encountered in the available datasets.

Furthermore the previous parser relied on a tool which extracted the formulas as stored in spreadsheets, while BumbleBee is used as an Excel add-in and therefore receives its formulas from Excel.
These formulas sometimes slightly differ in at least one aspect: when external files are referenced a numeric reference is stored while Excel provides either the filename or the file path and name.
Thus a formula could be received as \f{=[1]Sheet!A1} from the tool, and \f{=[File]Sheet!A1} or \f{='C:\textbackslash Path\textbackslash [File.xlxs]Sheet'!A1} by an Excel Add-In.
XLParser supports al three formats, while the previous parser only supported the first.

\subsection{AST improvements}

\subsubsection{Correctness}

While the AST correctness is unverified for both XLParser and the previous parser, several improvements have been made.
Operator precedence has been mentioned before, this was not taken into consideration in the previous parser version, providing very problematic in BumbleBee's use-case.
Several smaller corrections have also been made.
For example in the previous version \f{=F(1,,1)} and \f{=F(1,1)} produced an identical AST, while they have a different meaning, especially in the case of user defined functions.

\subsubsection{Homogenization}
The previous parser was constructed with a relatively clean base grammar, but over time rules were added in a fairly ad-hoc manner.
This caused the rules and therefore the AST to become quite messy in some cases.
XLParser solved this by reducing the grammar to a relatively clean grammar again.
However, this advantage is subjective and hard to quantify.
An example of this are User Defined Functions which produces a very different AST depending on whether they were internal \f{=UDF()} or external \f{=[1]UDF()}.
Another example are prefixes, all of the following used different tokens and productions rules: \f{=Sheet!A1}, \f{='Sheet'!A1}, \f{=[1]Sheet!A1} and \f{='[1]Sheet'!A1} while in XLParser the tokens are unformalized, and the production rules are cleaner in the authors opinion.


\section{Parser implementation}

The existing parsing was built using the Irony parser framework\footnote{https://irony.codeplex.com/}, which is a C\# parser generator that produces parsers based on the LALR(1) algorithm using a grammar defined in C\#.

Strictly speaking Irony produces a parse tree, however this tree is fairly high-level for a parse tree, leaving out elements such as punctuation and whitespace, and no separate AST is (currently) constructed in XLParser or BumbleBee, instead this tree is directly manipulated.
To avoid confusion and use usual nomenclature I will from now on refer to this tree as the AST.

\subsection{Lexical Analysis}
\label{sec:lexanalysis}

\begin{table}
\tiny
\centerfloat
%\advance\leftskip-1cm
\input{parsing/tokens.tex}
\caption{Lexical tokens used in the XLParser grammar, as refered to in section \ref{sec:lexanalysis}.}
\label{table:tokens}
\end{table}

Table \ref{table:tokens} contains the lexical tokens of the grammar, along with their identification patterns in a simple regular expression language. All tokens are case-insensitive.
Characters are defined as Unicode code points x9 (tab),xA (newline),xD (carriage return) and x20 (space) and upwards.

This grammar requires the parser to support token priorities, which Irony does.
Removing the necessity for token priorities is possible by altering the tokens and production rules, but makes the grammar more complicated and the resulting tree harder to use, thus being detrimental to design goals 2 and 3.

Some simple tokens (e.g. '\%', '!') are directly defined in the production rules in Figure \ref{figure:productions} in between quotes for readability and compactness.

\subsubsection{\textbf{Dates}}

The appearance of date and time values in spreadsheets depends on the presentation settings of cells. Internally, date and time values are stored as positive floating point numbers with the integer portion representing the number of days since a Jan 0 1900 epoch\footnote{Note that 1900 is incorrectly considered a leap year, due to a bug in Lotus 1-2-3 (first released in 1983) which was deliberately copied into the first Excel release and has since then been preserved for backwards compatibility reasons.} and the fractional portion representing the portion of the day passed.

When extracting formulas from spreadsheets, only the floating point value is available.
The parser will thus never see the formatted notation of the date.
For this reason, the grammar only parses numeric dates and times and these are not distinguishable from other numbers.

\newpage

\subsection{Syntactical Analysis}

\begin{figure}
\small
\begin{multicols*}{2}
\input{parsing/productionrules.tex}
\end{multicols*}
\caption{Production rules}
\label{figure:productions}
\end{figure}

The complete production rules of the grammar are listed in Extended BNF syntax in Figure \ref{figure:productions}.
Patterns inside \{ and \} can be repeated zero or more times.
The start symbol is $Start$. An example parse tree produced using this grammar is drawn in Figure \ref{figure:parsetrees}(b).

The \synt{Formula} rule covers all types of spreadsheet formula expressions: they can be constants (\texttt{=5}), references (\texttt{=A3}), function calls and operators (\texttt{=SUM(A1,A2)}), array constants (\texttt{=\{1,2;3,4\}} or reserved names (\texttt{=_xlnm.Print_Area}).
The \synt{Reference} rule covers a subset of expressions known as references expressions: internal or external cell and range references, functions and operators which can return references, named ranges, structured ranges and dynamic data exchanges.

%\begin{figure}
%	\caption{Syntax diagram of the \synt{Formula} production rule with most production rules expanded}
%	\label{figure:Formula}
%	%\centerfloat
%	\input{parsing/formula-diagram.tex}
%\end{figure}
%
%\begin{figure}
%	\caption{Syntax diagram of the \synt{Reference} production rule with most production rules expanded}
%	\label{figure:Reference}
%	\input{parsing/reference-diagram.tex}
%\end{figure}

\subsection{Precedence and ambiguity}
\label{sec:ambiguity}

\begin{table}
\small
\begin{tabular}{ll}
	\toprule
	Precedence & Operator(s) \\
	(higher is greater) & \\
	\midrule
	1 & = \textless \  \textgreater \  \textless= \  \textgreater= \  \textless\textgreater          \\
	2 & \&  \\
	3 & + - (binary) \\
	4 & $\ast$ / \\
	5 & \textasciicircum \\
	6 & \% \\
	7 & + - (unary) \\
	8 & , \\
	9 & \texttt{\char32} \\
	10 & : \\
	\bottomrule
\end{tabular}
\caption{Operator precedence in formulas}
\label{table:operatorprec}
\end{table}

\footnotetext{This is contrary to most other languages, where the exponentiation operator is right-associative. \\
In Excel \f{2\textasciicircum 1\textasciicircum 2} will be $(2^1)^2 = 4$, while in most other languages it will be $2^{1^2} = 2$}

The production rules are ambiguous, which means they cannot be directly used in a parser generator based on the LALR algorithm like Irony.

To resolve ambiguity with operators, e.g. whether to parse \f{=1+2*3} as \f{=(1+2)*3} or \f{=1+(2*3)}, operator precedence and associativity rules are defined.
These can be found in Table \ref{table:operatorprec}.

However, even with precedence and associativity rules the grammar is still not fully un-ambigious.
This is due to trade-offs on parsing references, see Section \ref{tradeoff:references}, and parsing unions (see section \ref{subsec:desing:unions}).
Ambiguity exists between the following production rules:
\begin{enumerate}
	\item \begin{grammar}<Reference> ::= `(' <Reference> `)'\end{grammar}
	\item \begin{grammar}<Union> ::= `(' <Reference> \{ `,' <Reference> \} `)'\end{grammar}
	\item \begin{grammar}<Formula> ::= `(' <Formula> `)'\end{grammar}
\end{enumerate}

A formula like \texttt{=(A1)} can be interpreted as either a bracketed reference, a union of one reference, or a reference within a bracketed formula.

In a LALR parser, which Irony produces, this ambiguity manifests in a state where, on a \texttt{')'} token, shifting on rule 1 and reducing on either rule 2 or 3 are possibilities, causing a shift-reduce conflict.
This was solved by instructing the parser generator to shift on rule 1 in case of this conflict, because this always is a correct interpretation and thus results in correct ASTs.

\newpage

\noindent
\begin{figure}[h!]
	\hspace*{0.003\textwidth}
	\input{implementation/refactoring-process-print}
	\caption{Section \ref{sec:printing} details AST pretty-printing, converting an AST to a string formula.}
\end{figure}

\section{Printing formula AST}
\label{sec:printing}

Printing a formula AST is the reverse operation of parsing, and is quite straightforward.
It can be done by describing for each tree node type how it can be translated back into a string, most of the time this is the exact reverse of the parser production rule.
Nodes with children need to know the printed form of their children, this can be satisfied by starting at the root of the tree and calling the print function recursively for each child.
A slightly simplified and compacted version of the XLParser code responsible for printing can be found in Appendix \ref{lst:xlparserprint}.

\section{Trade-offs}

The grammar presented in this chapter contains some trade-offs, partly due to the Excel language itself, partly due to design decisions.
These are detailed in this section.

\subsection{References}
\label{tradeoff:references}

References play an important role in the spreadsheet paradigm and therefore in the formula language.
In particular reference expressions, expressions which evaluate to a reference, are a subset of expressions and several operators and functions only accept reference expressions.
For example the formula \f{=SUM(IF(\ldots):A1)} is valid, while \f{=SUM((1+1):A1)} is not, because \f{IF} can return a reference while \f{+} cannot and the \f{:} operator only operates on references.

This is not unique to reference expressions, for example the operator \f{+} only operates on numeric values, making the expression \f{="a"+1} invalid.
What does make reference expressions special is how Excel treats them.
A formula which uses a non-reference expression where a reference expression is required, like the previously mentioned \f{=SUM((1+1):A1)}, will result in a parse error which means excel will not accept this formula from the user.
Meanwhile \f{="a"+1} will only result in a runtime error, an error value, but will be still parsed and evaluated.

For XLParser we had three options: do not concern ourselves with invalidly type expressions, incorporate the reference expression rules into the grammar, or implement a type system similar to how this would be done in a full compiler and reject invalidly typed expressions.
The first option is by far the simplest, but would result in a lot of invalid formulas being accepted, the second option would result in a more complicated grammar and might not even be possible, while the third option would result in an additional layer on top of the parser generator.

Because references are of great interest when analyzing formulas and already had additional grammar rules, the second option seemed to be achievable and acceptable and this is the route XLParser took and successfully implemented.
An additional downside of this approach turned out to be some additional ambiguity, as explained in Section \ref{sec:ambiguity}.

\subsection{Unions}
\label{subsec:desing:unions}

The comma serves both as an union operator and a function argument separator.
This proves challenging to correctly implement in a LALR(1) grammar.

A straightforward implementation would use production rules similar to this:
\begin{grammar}
<Union> ::= <Reference> `,' <Reference>

<Arguments> ::= <Argument> \{ `,' <Arguments> \}
\end{grammar}

However, this will cause a reduce-reduce conflict because the parser will have a state wherein it can reduce to both a \synt{Union} or \synt{Argument} on a \texttt{,} token.
Unfortunately there is no correct choice: in a formula like \texttt{=SUM(A1,1)} the parser must reduce on the \synt{Argument} nonterminal, while in a formula like \texttt{=A1,A1} the parser must reduce to the \synt{Union} nonterminal.
With the above production rules a LALR(1) parser could not correctly parse the language.

The presented grammar only parsers unions in between parentheses, e.g. \texttt{=SMALL((A1,A2),1)}.
This is a trade-off between a lower compatibility (design goal 1) and an easier implementation (design goal 3).
This lower compatibility is deemed acceptable, because unions are only extremely rarely used.
In the evaluation as described in Chapter \ref{chapter:evaluation} unions were only encountered in 0.002\% of formulas.

Additionally formulas that this grammar does not parse often result in an error value after evaluation in Excel.
For example \texttt{=A1,A1} does parse in Excel, but produces the error \texttt{\#VALUE!} on evaluation.

Implementing the straightforward rules above, while desirable, is not possible without using a more powerful grammar class.