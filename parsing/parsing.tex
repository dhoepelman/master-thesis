% !TeX root = ../thesis.tex
% !TeX spellcheck = en_US

\chapter{Parsing spreadsheet formulas}
\label{chapter:parsing}

\noindent
\begin{figure}[h]
\centerfloat
\input{parsing/refactoring-process-parsing}
\caption{Overview of the refactoring process}
\label{fig:chapterparsingintrofigure}
\end{figure}


\noindent
This chapter details parsing, converting a string formula to an AST, shown boxed in Figure \ref{fig:chapterparsingintrofigure}.
It assumes the reader is familiar with basic parser theory, a good overview of which can be found in \cite{dragonbook}.

\section{Motivation}
\label{sec:motivation}

In order to implement refactorings of spreadsheets, a refactoring tool must be able to manipulate spreadsheets.
The usual way to implement refactorings is by manipulating the original program's AST until it represents the desired program, and then print that back to a string.
Excel exposes an API to retrieve and update the contents of a spreadsheet file, but this API only provides access to formula strings, and does not expose its parser or formula ASTs representations.
Because of this, a refactoring tool needs to contain a parser for Excel formulas.

BumbleBee relied on a parser developed over the years for previous research, however this parser had accrued technical debt due to new rules being added over time, sometimes in an inconsistent manner or not supporting the whole language.
Furthermore the parser interpreted some language constructs wrong and missed several features, which made implementing refactorings hard and error-prone.
For example, operator precedence was not taken into account, causing the formula \f{=A1 + A2 * A3} to be parsed as \f{=(A1 + A2) * A3}.
The existing parser thus was insufficient to correctly implement the refactorings presented in this thesis.
Thus an additional goal for this thesis became to create a better parser.

For BumbleBee and other research on spreadsheet formulas the following design goals were formulated for the parser and grammar within the Spreadsheet lab group:

\begin{enumerate}
\label{sec:designgoals}
\item The parser must be compatible with the official language
\item Produced parse trees must be suited for further manipulation and analysis with minimal post-processing required
\item The grammar must be compact enough to feasibly implement with a parser generator
\end{enumerate}

While an official grammar for Excel formulas is published \cite{ExcelOfficialGrammar}, it does not meet the above requirements for two reasons.
Firstly, it is over 30 pages long and contains hundreds of production rules and thus fails Requirement 3.
Secondly, because of the detail of the grammar and the large number of production rules the resulting parse trees are very complex and fail requirement 2.

Because there is no suitable parser and grammar available that satisfy the above requirements, we decided to clean up and partially rewrite the parser.
The end result of this effort is an independent, open-source parser for Excel formulas called XLParser\footnote{https://github.com/PerfectXL/XLParser}, about which a paper was published in IEEE conference SCAM 2015 \cite{xlparser}.

\section{Parser implementation}

The existing parsing was built using the Irony parser framework\footnote{https://irony.codeplex.com/}, which is a C\# parser generator that produces parsers based on the LALR(1) algorithm using a grammar defined in C\#.

Strictly speaking Irony produces a parse tree, however this tree is fairly high-level for a parse tree, leaving out elements such as punctuation and whitespace, and no separate AST is (currently) constructed in XLParser or BumbleBee, instead this tree is directly manipulated.
To avoid confusion and use usual nomenclature we will from now on refer to this tree as the AST.

\subsection{Lexical Analysis}
\label{sec:lexanalysis}

\begin{table}
\tiny
\centerfloat
%\advance\leftskip-1cm
\input{parsing/tokens.tex}
\caption{Lexical tokens used in the XLParser grammar}
\label{table:tokens}
\end{table}

Table \ref{table:tokens} contains the lexical tokens of the grammar, along with their identification patterns in a simple regular expression language. All tokens are case-insensitive.
Characters are defined as Unicode code points x9 (tab), xA (newline), xD (carriage return) and x20 (space) and upwards.

This grammar requires the parser to support token priorities, which Irony does.
Removing the necessity for token priorities is possible by altering the tokens and production rules, but makes the grammar more complicated and the resulting tree harder to use, thus being detrimental to design goals 2 and 3.

Some simple tokens (e.g. '\%', '!') are directly defined in the production rules in Figure \ref{figure:productions} in between quotes for readability and compactness.

\subsubsection{\textbf{Dates}}

The appearance of date and time values in spreadsheets depends on the presentation settings of cells. Internally, date and time values are stored as positive floating point numbers with the integer portion representing the number of days since a Jan 0 1900 epoch\footnote{Note that 1900 is incorrectly considered a leap year, due to a bug in Lotus 1-2-3 (first released in 1983) which was deliberately copied into the first Excel release and has since then been preserved for backwards compatibility reasons.} and the fractional portion representing the portion of the day passed.

When extracting formulas from spreadsheets, only the floating point value is available.
The parser will thus never encounter the formatted notation of the date.
For this reason, the grammar only parses numeric dates and times and these are not distinguishable from other numbers.

\newpage

\subsection{Syntactical Analysis}

\begin{figure}
\small
\begin{multicols*}{2}
\input{parsing/productionrules.tex}
\end{multicols*}
\caption{Production rules used in the XLParser grammar}
\label{figure:productions}
\end{figure}

The complete production rules of the grammar are listed in Extended BNF syntax in Figure \ref{figure:productions}.
Patterns between \{ and \} can be repeated zero or more times.
The start symbol is $Start$.
%An example parse tree produced using this grammar is drawn in Figure \ref{figure:parsetrees}(b).

The \synt{Formula} rule covers all the expressions which can be used in spreadsheet formulas: constants (\texttt{=5}), references (\texttt{=A3}), function calls and operators (\texttt{=SUM(A1,A2)}), array constants (\texttt{=\{1,2;3,4\}} and reserved names (\texttt{=_xlnm.Print_Area}).
The \synt{Reference} rule covers a subset of expressions known as references expressions, expressions which can return a reference.
These can be internal or external cell and range references, functions and operators which can return references, named ranges, structured references and dynamic data exchanges.

%\begin{figure}
%	\caption{Syntax diagram of the \synt{Formula} production rule with most production rules expanded}
%	\label{figure:Formula}
%	%\centerfloat
%	\input{parsing/formula-diagram.tex}
%\end{figure}
%
%\begin{figure}
%	\caption{Syntax diagram of the \synt{Reference} production rule with most production rules expanded}
%	\label{figure:Reference}
%	\input{parsing/reference-diagram.tex}
%\end{figure}

\subsection{Precedence and ambiguity}
\label{sec:ambiguity}

\begin{table}
\small
\centering
\begin{tabular}{lll}
	\toprule
	Precedence & Operator(s) & Description \\
	\midrule
	1 & = \textless \  \textgreater \  \textless= \  \textgreater= \  \textless\textgreater   & Logical comparison       \\
	2 & \& & Text concatenation \\
	3 & + - (binary) & Addition and subtraction \\
	4 & $\ast$ / & Multiplication and division \\
	5 & \textasciicircum & Exponentiation \\
	6 & \% & Division by 100 \\
	7 & + - (unary) & No effect and inverting number sign \\
	8 & , & Range union \\
	9 & \texttt{\char32} & Range intersection \\
	10 & : & Range construction \\
	\bottomrule
\end{tabular}
\caption{Operator precedence in formulas, with larger numbers indicating higher precedence}
\label{table:operatorprec}
\end{table}

\footnotetext{This is contrary to most other languages, where the exponentiation operator is right-associative. \\
In Excel \f{2\textasciicircum 1\textasciicircum 2} will be $(2^1)^2 = 4$, while in most other languages it will be $2^{1^2} = 2$}

The production rules are ambiguous, which means they cannot be directly used in a parser generator based on the LALR(1) algorithm like Irony.

To resolve ambiguity with operators, e.g. whether to parse \f{=1+2*3} as \f{=(1+2)*3} or \f{=1+(2*3)}, operator precedence and associativity rules are defined.
These can be found in Table \ref{table:operatorprec}.

However, even with precedence and associativity rules the grammar is still not fully un-ambigious.
This is due to trade-offs on parsing references ( see Section \ref{tradeoff:references}) and parsing unions (see Section \ref{subsec:desing:unions}).
Ambiguity exists between the following production rules:
\begin{enumerate}
	\item \begin{grammar}<Reference> ::= `(' <Reference> `)'\end{grammar}
	\item \begin{grammar}<Union> ::= `(' <Reference> \{ `,' <Reference> \} `)'\end{grammar}
	\item \begin{grammar}<Formula> ::= `(' <Formula> `)'\end{grammar}
\end{enumerate}

A formula like \texttt{=(A1)} can be interpreted as either a bracketed reference, a union of one reference, or a reference within a bracketed formula.

In a LALR(1) parser, which Irony produces, this ambiguity manifests in a state where, on a \texttt{')'} token, shifting on rule 1 and reducing on either rule 2 or 3 are possibilities, causing a shift-reduce conflict.
This was solved by instructing the parser generator to shift on rule 1 in case of this conflict, because this always is a correct interpretation and thus results in correct ASTs.

\newpage

\noindent
\begin{figure}[h!]
	\hspace*{0.003\textwidth}
	\input{implementation/refactoring-process-print}
	%\caption{Section \ref{sec:printing} details AST pretty-printing, converting an AST to a string formula}
	\caption{Overview of the refactoring process}
	\label{fig:chapterparsingintrofigure}
\end{figure}

\section{Pretty-printing the formula AST}
\label{sec:printing}

Pretty-printing a formula AST is the reverse operation of parsing, and must be done to convert a refactored AST back to a string as seen in Figure \ref{fig:chapterparsingintrofigure}.

Pretty-printing is quite straightforward: it can be done by describing for each tree node type how it can be translated back into a string, most of the time this is the exact reverse of the parser production rule.
Printing is done by starting at the root of the tree and calling the print function recursively for each child, because nodes with children need to know the printed form of their children.
A slightly simplified and compacted version of the XLParser code responsible for printing can be found in Appendix \ref{lst:xlparserprint}.

\section{Trade-offs}

The grammar presented in this chapter contains some trade-offs, partly due to the Excel language itself, partly due to design decisions.
These are detailed in this section.

\subsection{References}
\label{tradeoff:references}

References play an important role in the spreadsheet paradigm and therefore in the formula language.
Particularly reference expressions, expressions which evaluate to a reference, are a subset of expressions and several operators and functions only accept reference expressions.
For example the formula \f{=SUM(IF(\ldots):A1)} is valid, while \f{=SUM((1+1):A1)} is not, because \f{IF} can return a reference while \f{+} cannot and the \f{:} operator only operates on references.

This is not unique to reference expressions, for example the operator \f{+} only operates on numeric values, making the expression \f{="a"+1} invalid.
What does make reference expressions special is how Excel treats them.
A formula which uses a non-reference expression where a reference expression is required, like the previously mentioned \f{=SUM((1+1):A1)}, will result in a parse error which means excel will not accept this formula from the user.
By contrast, \f{="a"+1} will only result in the runtime error \f{\#VALUE!}, but will still be parsed and evaluated.

\newpage

For XLParser we had three options: do not concern ourselves with invalidly type expressions, incorporate the reference expression rules into the grammar, or implement a type system similar to how this would be done in a full compiler and reject invalidly typed expressions.
The first option is by far the simplest, but would result in a lot of invalid formulas being accepted, the second option would result in a more complicated grammar and might not even be possible, while the third option would result in an additional layer on top of the parser generator.

Because references are of great interest when analyzing formulas and already had additional grammar rules, the second option seemed to be achievable and acceptable and this is the route XLParser took and successfully implemented.
A downside of this approach turned out to be some additional ambiguity, as explained in Section \ref{sec:ambiguity}.

\subsection{Unions}
\label{subsec:desing:unions}

The comma serves both as the union operator and the function argument separator.
This proves challenging to correctly implement in a LALR(1) grammar.

\noindent A straightforward implementation would use production rules similar to this:
\begin{grammar}
<Union> ::= <Reference> `,' <Reference>

<Arguments> ::= <Argument> \{ `,' <Arguments> \}
\end{grammar}

However, this will cause a reduce-reduce conflict because the parser will have a state wherein it can reduce to both a \synt{Union} or \synt{Argument} on a \texttt{,} token.
Unfortunately there is no correct choice: in a formula like \texttt{=SUM(A1,1)} the parser must reduce on the \synt{Argument} nonterminal, while in a formula like \texttt{=A1,A1} the parser must reduce to the \synt{Union} nonterminal.
With the above production rules a LALR(1) parser could not correctly parse the language.

The presented grammar only parsers unions in between parentheses, e.g. \texttt{=SMALL((A1,A2),1)}.
This is a trade-off between a lower compatibility (design goal 1) and an easier implementation (design goal 3).
This lower compatibility is deemed acceptable, because unions are only extremely rarely used.
In the evaluation as described in Chapter \ref{chapter:evaluation} unions were only encountered in 0.002\% of formulas.

Additionally formulas that this grammar does not parse often result in an error value after evaluation in Excel.
For example \texttt{=A1,A1} does parse in Excel, but produces the error \texttt{\#VALUE!} on evaluation.

Implementing the straightforward rules above, while desirable, is not possible without using a more powerful grammar class.

\newpage

\section{Improvements over existing parser}

Improvements made to XLParser compared to the existing parser fall into the following categories:

\subsubsection{More frequent rejecting of invalid formulas}

XLParser is often less forgiving than the previous parser, and rejects more types of invalid formulas.
This is most prominently noticable in reference expressions, becaues the old parser does not differentiate between reference and non-reference expressions.
Therefore formulas like \f{=1 1} and \f{=LARGE((1,2,3),4)} are considered valid, while they are not and would be rejected by Excel.

\subsubsection{Broader parsing of valid formulas}

As detailed in Chapter \ref{chapter:evaluation}, XLParser has a very high parse success rate.

Several language features were absent in the previous parser.
Examples are ranges with multiple limits (\f{=SUM(A1:B2:C3:D4)}), structured table references (\f{=TableName[ColumnName]}), array constants \f{=SUM(\{1,2,3\})} and functions in reference expression (\f{=SUM(IF(TRUE,A1,B2):C5)}).

Furthermore the previous parser relied on a tool which extracted the formulas as stored in spreadsheets, while BumbleBee is used as an Excel add-in and therefore receives its formulas from Excel.
These formulas sometimes slightly differ in at least one aspect: when external files are referenced a numeric reference is stored while Excel provides either the filename or the file path and name.
Thus a formula could be received as \f{=[1]Sheet!A1} from the tool, and \f{=[File]Sheet!A1} or \f{='C:\textbackslash Path\textbackslash [File.xlxs]Sheet'!A1} by an Excel Add-In.
XLParser supports al three formats, while the previous parser only supported the first.

\subsubsection{AST improvements}

\subsubsubsection{Correctness}

While the AST correctness is unverified for both XLParser and the previous parser, several improvements have been made.
Operator precedence has been mentioned before, this was not taken into consideration in the previous parser version, providing very problematic in BumbleBee's use-case.
Several smaller corrections have also been made.
For example in the previous version \f{=F(1,,1)} and \f{=F(1,1)} produced an identical AST, while they have a different meaning, especially in the case of user defined functions.

\noindent\subsubsubsection{Homogenization}

The previous parser was constructed with a clean base grammar, but over time additions were made to deal with constructs which could not be parsed.
This caused the rules and therefore the AST to become inconsistent.
XLParser solves this by reducing the grammar to a clean grammar again and removing inconsistencies.
However, this advantage is subjective and hard to quantify.
An example of this are user defined functions which produced a different AST depending on whether they were internal \f{=UDF()} or external \f{=[1]UDF()}.
Another example are prefixes, all of the following used different tokens and productions rules: \f{=Sheet!A1}, \f{='Sheet'!A1}, \f{=[1]Sheet!A1} and \f{='[1]Sheet'!A1} while in XLParser the tokens are unformalized, and the production rules are cleaner in the authors opinion.